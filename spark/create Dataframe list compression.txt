from pyspark.sql import DataFrame
from functools import reduce


# dictionary of dataframen example: DataFrames = {"df_1":data_set_1, "df_2":data_set_2}

df_temp = reduce(DataFrame.unionAll, [DataFrames[index] for index in DataFrames.keys()])


# create identity list compression
value = [i for i in range(init_value , end_value)]
df = spark.createDataFrame(value, IntegerType()).toDF(column)
